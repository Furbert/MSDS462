{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Module_1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMWo8XLxosL4yxcRr3vdY5v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Furbert/MSDS462/blob/master/Module_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woiMNpOgzfY9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "7fdb5b9c-e2c3-497d-9f1c-28c4cc799351"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive' , force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtQhtwzzz4GG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6af46d63-bf8b-463b-9bc1-fb1ac19fe7f0"
      },
      "source": [
        "import os;os.listdir('/content/gdrive/My Drive/Computer_Vision/awsml')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['config', 'kaggle.json', 'credentials']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-i9UYZz0ccx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "481d1cf8-be5c-4ec6-f1b0-c7893b090c21"
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.11.28)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.6.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbpBJdtq16oF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/gdrive/My\\ Drive/Computer_Vision/awsml/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPRrHY_s2U_c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "dcfe40a3-3add-496c-d77c-f0d4031e7703"
      },
      "source": [
        "!kaggle datasets download -d oddrationale/mnist-in-csv\n",
        "!ls -l /content/\n",
        "!unzip /content/mnist-in-csv.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading mnist-in-csv.zip to /content\n",
            " 59% 9.00M/15.2M [00:00<00:00, 18.5MB/s]\n",
            "100% 15.2M/15.2M [00:00<00:00, 31.0MB/s]\n",
            "total 15608\n",
            "drwx------ 4 root root     4096 Jan 12 02:47 gdrive\n",
            "-rw-r--r-- 1 root root 15970596 Jan 12 02:47 mnist-in-csv.zip\n",
            "drwxr-xr-x 1 root root     4096 Dec 18 16:52 sample_data\n",
            "Archive:  /content/mnist-in-csv.zip\n",
            "  inflating: mnist_test.csv          \n",
            "  inflating: mnist_train.csv         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkTVpXwF4m2u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/mnist_train.csv')\n",
        "test = pd.read_csv('/content/mnist_test.csv')\n",
        "df_train = train.copy()\n",
        "df_test = test.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQMkYeok5TKH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "34bd8167-2523-441b-d0bb-f88e3495268a"
      },
      "source": [
        "print(df_train.shape)\n",
        "print(df_test.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 785)\n",
            "(10000, 785)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6V45_aq5u38",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "52a47176-0950-499f-8c1f-0fb3cd9a0f11"
      },
      "source": [
        "\n",
        "# Ignore warnings :\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "# Handle table-like data and matrices :\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math \n",
        "import itertools\n",
        "\n",
        "\n",
        "\n",
        "# Modelling Algorithms :\n",
        "\n",
        "# Classification\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier , GradientBoostingClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis , QuadraticDiscriminantAnalysis\n",
        "\n",
        "# Regression\n",
        "from sklearn.linear_model import LinearRegression,Ridge,Lasso,RidgeCV, ElasticNet\n",
        "from sklearn.ensemble import RandomForestRegressor,BaggingRegressor,GradientBoostingRegressor,AdaBoostRegressor \n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Modelling Helpers :\n",
        "from sklearn.preprocessing import  Normalizer , scale\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.model_selection import GridSearchCV , KFold , cross_val_score\n",
        "\n",
        "\n",
        "\n",
        "#preprocessing :\n",
        "from sklearn.preprocessing import MinMaxScaler , StandardScaler,  LabelEncoder\n",
        "\n",
        "\n",
        "\n",
        "#evaluation metrics :\n",
        "\n",
        "# Regression\n",
        "from sklearn.metrics import mean_squared_log_error,mean_squared_error, r2_score,mean_absolute_error \n",
        "\n",
        "# Classification\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score  \n",
        "\n",
        "\n",
        "# Deep Learning Libraries\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau, LearningRateScheduler\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "\n",
        "# Visualisation\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pylab as pylab\n",
        "import seaborn as sns\n",
        "import missingno as msno\n",
        "\n",
        "\n",
        "\n",
        "# Configure visualisations\n",
        "%matplotlib inline\n",
        "mpl.style.use( 'ggplot' )\n",
        "plt.style.use('fivethirtyeight')\n",
        "sns.set(context=\"notebook\", palette=\"dark\", style = 'whitegrid' , color_codes=True)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0ywS1gz7brE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setting Random Seeds for Reproducibilty.\n",
        "seed = 66\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5th9HRHY7wJL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = train.iloc[:,1:]\n",
        "Y = train.iloc[:,0]\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZ90VcNw8BOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshape(examples, height, width, channels)\n",
        "x_train = x_train.values.reshape((-1, 28, 28, 1))\n",
        "x_test = x_test.values.reshape((-1, 28, 28, 1))\n",
        "\n",
        "df_test.drop('label', axis=1, inplace=True)\n",
        "df_test = df_test.values.reshape((-1, 28, 28, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1AQ6P878qUJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.astype(\"float32\")/255\n",
        "x_test = x_test.astype(\"float32\")/255\n",
        "df_test = df_test.astype(\"float32\")/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoE2p7Y2835j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Z4hUXJt9BC9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "80105baf-d65f-42e4-98ef-0c30396fdb86"
      },
      "source": [
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(54000, 10)\n",
            "(6000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1DlLKO49I7Q",
        "colab_type": "text"
      },
      "source": [
        "## Train CNN\n",
        "#### Borrowed CNN model from: https://www.kaggle.com/cdeotte/25-million-images-0-99757-mnist#"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tVZ74KQ9OVA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "fc75fa89-9401-425f-9b9d-6251df2bb754"
      },
      "source": [
        "# Building a ConvNet\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', strides=1, padding='same', \n",
        "                 data_format='channels_last', input_shape=(28,28,1)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', strides=1, padding='same', \n",
        "                 data_format='channels_last'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', strides=1, padding='same', \n",
        "                 data_format='channels_last'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "    \n",
        "    \n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', strides=1, padding='same', \n",
        "                 data_format='channels_last'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaUI9EhP9dKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Optimizer\n",
        "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkXuMe-r9ltS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "42e53a25-ff2f-4fe2-a118-40c366b8f1d9"
      },
      "source": [
        "# Compiling the model\n",
        "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT7mn0Bz9woi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "outputId": "4112eba7-55ac-453f-a428-a47db6b9dac8"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 28, 28, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 28, 28, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 14, 14, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 14, 14, 128)       512       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               12845568  \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 13,017,770\n",
            "Trainable params: 13,016,106\n",
            "Non-trainable params: 1,664\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ka4CidH795Q3",
        "colab_type": "text"
      },
      "source": [
        "## Rate Decay\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFnmQBc399Jn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reduce_lr = LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twQ2w5Yw-Dfh",
        "colab_type": "text"
      },
      "source": [
        "## Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oJ5hQYI-HSQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        rotation_range = 8,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        shear_range = 0.3,# shear angle in counter-clockwise direction in degrees  \n",
        "        width_shift_range=0.08,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.08,  # randomly shift images vertically (fraction of total height)\n",
        "        vertical_flip=True)  # randomly flip images\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bKj5Pbc-yNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTsL-Xxw-5Wq",
        "colab_type": "text"
      },
      "source": [
        "## Fit the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVEcLQv_-9YB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 40"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykjzD3fW_Eh5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4be1f0c7-7e6a-4a9c-ea17-c1322f4df201"
      },
      "source": [
        "# Fit the Model\n",
        "history = model.fit_generator(datagen.flow(x_train, y_train, batch_size = batch_size), epochs = epochs, \n",
        "                              validation_data = (x_test, y_test), verbose=2, \n",
        "                              steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "                              callbacks = [reduce_lr])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/40\n",
            " - 578s - loss: 0.5929 - acc: 0.8109 - val_loss: 0.0953 - val_acc: 0.9713\n",
            "Epoch 2/40\n",
            " - 577s - loss: 0.2143 - acc: 0.9343 - val_loss: 0.1236 - val_acc: 0.9618\n",
            "Epoch 3/40\n",
            " - 576s - loss: 0.1612 - acc: 0.9504 - val_loss: 0.0726 - val_acc: 0.9758\n",
            "Epoch 4/40\n",
            " - 571s - loss: 0.1383 - acc: 0.9584 - val_loss: 0.0597 - val_acc: 0.9807\n",
            "Epoch 5/40\n",
            " - 572s - loss: 0.1229 - acc: 0.9625 - val_loss: 0.0586 - val_acc: 0.9815\n",
            "Epoch 6/40\n",
            " - 571s - loss: 0.1077 - acc: 0.9664 - val_loss: 0.0564 - val_acc: 0.9795\n",
            "Epoch 7/40\n",
            " - 571s - loss: 0.0993 - acc: 0.9699 - val_loss: 0.0449 - val_acc: 0.9847\n",
            "Epoch 8/40\n",
            " - 570s - loss: 0.0878 - acc: 0.9731 - val_loss: 0.0511 - val_acc: 0.9838\n",
            "Epoch 9/40\n",
            " - 570s - loss: 0.0851 - acc: 0.9739 - val_loss: 0.0451 - val_acc: 0.9840\n",
            "Epoch 10/40\n",
            " - 569s - loss: 0.0817 - acc: 0.9749 - val_loss: 0.0426 - val_acc: 0.9860\n",
            "Epoch 11/40\n",
            " - 570s - loss: 0.0767 - acc: 0.9753 - val_loss: 0.0467 - val_acc: 0.9840\n",
            "Epoch 12/40\n",
            " - 569s - loss: 0.0718 - acc: 0.9777 - val_loss: 0.0389 - val_acc: 0.9870\n",
            "Epoch 13/40\n",
            " - 570s - loss: 0.0695 - acc: 0.9793 - val_loss: 0.0343 - val_acc: 0.9882\n",
            "Epoch 14/40\n",
            " - 570s - loss: 0.0680 - acc: 0.9792 - val_loss: 0.0326 - val_acc: 0.9877\n",
            "Epoch 15/40\n",
            " - 569s - loss: 0.0632 - acc: 0.9802 - val_loss: 0.0353 - val_acc: 0.9880\n",
            "Epoch 16/40\n",
            " - 570s - loss: 0.0626 - acc: 0.9805 - val_loss: 0.0326 - val_acc: 0.9905\n",
            "Epoch 17/40\n",
            " - 570s - loss: 0.0591 - acc: 0.9813 - val_loss: 0.0324 - val_acc: 0.9885\n",
            "Epoch 18/40\n",
            " - 569s - loss: 0.0568 - acc: 0.9827 - val_loss: 0.0379 - val_acc: 0.9873\n",
            "Epoch 19/40\n",
            " - 570s - loss: 0.0578 - acc: 0.9824 - val_loss: 0.0344 - val_acc: 0.9883\n",
            "Epoch 20/40\n",
            " - 569s - loss: 0.0528 - acc: 0.9836 - val_loss: 0.0333 - val_acc: 0.9892\n",
            "Epoch 21/40\n",
            " - 572s - loss: 0.0543 - acc: 0.9834 - val_loss: 0.0291 - val_acc: 0.9897\n",
            "Epoch 22/40\n",
            " - 570s - loss: 0.0528 - acc: 0.9838 - val_loss: 0.0314 - val_acc: 0.9888\n",
            "Epoch 23/40\n",
            " - 568s - loss: 0.0525 - acc: 0.9839 - val_loss: 0.0314 - val_acc: 0.9888\n",
            "Epoch 24/40\n",
            " - 570s - loss: 0.0503 - acc: 0.9846 - val_loss: 0.0328 - val_acc: 0.9890\n",
            "Epoch 25/40\n",
            " - 571s - loss: 0.0473 - acc: 0.9856 - val_loss: 0.0292 - val_acc: 0.9897\n",
            "Epoch 26/40\n",
            " - 570s - loss: 0.0479 - acc: 0.9845 - val_loss: 0.0291 - val_acc: 0.9897\n",
            "Epoch 27/40\n",
            " - 569s - loss: 0.0454 - acc: 0.9859 - val_loss: 0.0297 - val_acc: 0.9900\n",
            "Epoch 28/40\n",
            " - 569s - loss: 0.0468 - acc: 0.9854 - val_loss: 0.0303 - val_acc: 0.9892\n",
            "Epoch 29/40\n",
            " - 569s - loss: 0.0475 - acc: 0.9853 - val_loss: 0.0290 - val_acc: 0.9903\n",
            "Epoch 30/40\n",
            " - 570s - loss: 0.0442 - acc: 0.9858 - val_loss: 0.0286 - val_acc: 0.9903\n",
            "Epoch 31/40\n",
            " - 570s - loss: 0.0463 - acc: 0.9859 - val_loss: 0.0274 - val_acc: 0.9902\n",
            "Epoch 32/40\n",
            " - 570s - loss: 0.0424 - acc: 0.9868 - val_loss: 0.0292 - val_acc: 0.9905\n",
            "Epoch 33/40\n",
            " - 571s - loss: 0.0452 - acc: 0.9866 - val_loss: 0.0283 - val_acc: 0.9902\n",
            "Epoch 34/40\n",
            " - 570s - loss: 0.0433 - acc: 0.9865 - val_loss: 0.0281 - val_acc: 0.9910\n",
            "Epoch 35/40\n",
            " - 570s - loss: 0.0436 - acc: 0.9861 - val_loss: 0.0267 - val_acc: 0.9907\n",
            "Epoch 36/40\n",
            " - 569s - loss: 0.0436 - acc: 0.9864 - val_loss: 0.0284 - val_acc: 0.9902\n",
            "Epoch 37/40\n",
            " - 570s - loss: 0.0432 - acc: 0.9868 - val_loss: 0.0279 - val_acc: 0.9907\n",
            "Epoch 38/40\n",
            " - 571s - loss: 0.0410 - acc: 0.9874 - val_loss: 0.0281 - val_acc: 0.9898\n",
            "Epoch 39/40\n",
            " - 569s - loss: 0.0385 - acc: 0.9875 - val_loss: 0.0276 - val_acc: 0.9902\n",
            "Epoch 40/40\n",
            " - 571s - loss: 0.0419 - acc: 0.9869 - val_loss: 0.0273 - val_acc: 0.9905\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiQhrf6e021D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "914c9f94-373e-4f74-e700-f6a230bf11b6"
      },
      "source": [
        "score = model.evaluate(x_test, y_test)\n",
        "\n",
        "print('Loss: {:.4f}'.format(score[0]))\n",
        "print('Accuracy: {:.4f}'.format(score[1]))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6000/6000 [==============================] - 17s 3ms/step\n",
            "Loss: 0.0273\n",
            "Accuracy: 0.9905\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}